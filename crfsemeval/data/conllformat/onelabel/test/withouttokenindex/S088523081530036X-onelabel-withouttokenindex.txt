Note NN I-NP O
that IN I-PP O
the DT I-NP O
presented JJ I-NP O
architecture NN I-NP O
works VBZ I-VP O
at IN I-PP O
the DT I-NP O
frame NN I-NP O
level, JJ I-NP O
meaning NN I-NP O
that IN I-PP O
each DT I-NP O
single JJ I-NP O
frame NN I-NP O
(plus CC O O
its PRP$ I-NP O
corresponding JJ I-NP O
context) NN I-NP O
is VBZ I-VP O
fed-forward JJ I-NP O
through IN I-PP O
the DT I-NP O
network, JJ I-NP O
obtaining VBG I-VP O
a DT I-NP O
class NN I-NP O
posterior JJ I-NP O
probability NN I-NP O
for IN I-PP O
all DT I-NP O
of IN I-PP O
the DT I-NP O
target NN I-NP I-M
languages. NN I-NP I-M

This DT I-NP O
fact NN I-NP O
makes VBZ I-VP O
the DT I-NP O
DNNs NNP I-NP I-P
particularly RB O O
suitable JJ I-NP O
for IN I-PP O
real-time JJ I-NP O
applications NNS I-NP O
because, VBP I-VP O
unlike IN I-PP O
other JJ I-NP I-P
approaches NNS I-NP I-P
(i.e. JJ I-NP O
i-vectors), JJ I-NP O
we PRP B-NP O
can MD I-VP O
potentially RB I-VP O
make VB I-VP O
a DT I-NP O
decision NN I-NP O
about IN I-PP O
the DT I-NP O
language NN I-NP O
at IN I-PP O
each DT I-NP O
new JJ I-NP O
frame. NN I-NP O

Indeed, NNP I-NP O
at IN I-PP O
each DT I-NP O
frame, NN I-NP O
we PRP B-NP O
can MD I-VP O
combine VB I-VP I-P
the DT I-NP I-P
evidence NN I-NP I-P
from IN I-PP I-P
past JJ I-NP I-P
frames NNS I-NP I-P
to TO I-VP O
get VB I-VP O
a DT I-NP O
single JJ I-NP O
similarity NN I-NP O
score NN I-NP O
between IN I-PP O
the DT I-NP O
test NN I-NP O
utterance NN I-NP O
and CC O O
the DT I-NP O
targetlanguages. NN I-NP O

A DT I-NP O
simple JJ I-NP O
way NN I-NP O
of IN I-PP O
doing VBG I-VP O
this DT I-NP O
combination NN I-NP O
is VBZ I-VP O
to TO I-VP O
assume VB I-VP I-P
that IN I-PP I-P
frames NNS I-NP I-P
are VBP I-VP I-P
independent JJ I-NP I-P
and CC O I-P
multiply VB I-VP I-P
the DT I-NP I-P
posterior JJ I-NP I-P
estimates NNS I-NP I-P
of IN I-PP I-P
the DT I-NP I-P
last JJ I-NP I-P
layer. NN I-NP I-P

The DT I-NP O
score NN I-NP O
sl NN I-NP O
for IN I-PP O
language NN I-NP O
l NN I-NP O
of IN I-PP O
a DT I-NP O
given VBN I-NP O
test NN I-NP I-M
utterance NN I-NP I-M
is VBZ I-VP O
computed VBN I-VP O
by IN I-PP O
multiplying VBG I-VP I-P
the DT I-NP I-P
output NN I-NP I-P
probabilities NNS I-NP I-P
pl VBP I-VP I-P
obtained VBN I-VP I-P
for IN I-PP I-P
all DT I-NP I-P
of IN I-PP I-P
its PRP$ I-NP I-P
frames; NN I-NP I-P
or CC O O
equivalently, NN I-NP O
accumulating VBG I-NP I-P
the DT B-NP I-P
logs NNS I-NP I-P
as:(6)sl=1N∑t=1Nlogp(Ll|xt​, VBP I-VP I-P
θ)where RB I-VP O
p(Ll|xt​, JJ I-NP O
θ) NN I-NP O
represents VBZ I-VP O
the DT I-NP O
class NN I-NP O
probability NN I-NP O
output NN I-NP O
for IN I-PP O
the DT I-NP O
language NN I-NP O
l NN I-NP O
corresponding VBG I-VP O
to TO I-VP O
the DT I-NP O
input NN I-NP O
example NN I-NP O
at IN I-PP O
time NN I-NP O
t, NN I-NP O
xt NN I-NP O
by IN I-PP O
using VBG I-VP O
the DT I-NP O
DNN NNP I-NP I-P
defined VBN I-VP O
by IN I-PP O
parameters NNS I-NP O
θ. NNS I-NP O

